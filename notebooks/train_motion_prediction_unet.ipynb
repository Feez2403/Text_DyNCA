{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xI10CZklT41k"
      },
      "source": [
        "# Motion Prediction UNet Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install py-lz4framed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "from models.ImageToVec import UNet\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import lz4framed\n",
        "import pickle\n",
        "\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from utils.misc.flow_viz import plot_vec_field\n",
        "\n",
        "def load_compressed_tensor(filename):\n",
        "    retval = None\n",
        "    with open(filename, mode='rb') as file:\n",
        "        retval = torch.from_numpy(pickle.loads(lz4framed.decompress(file.read())))\n",
        "    return retval\n",
        "\n",
        "\n",
        "img_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageVectorFlowDataset(Dataset):\n",
        "    def __init__(self, img_size, path):\n",
        "        self.img_size = img_size\n",
        "        self.path = path\n",
        "        self.imgs = []\n",
        "        self.vecs = []\n",
        "        self.resize = T.Resize(self.img_size[0])\n",
        "        self.load_data()\n",
        "    \n",
        " \n",
        "    \n",
        "    def load_data(self):\n",
        "        print(\"Loading data...\")\n",
        "        for file in tqdm(os.listdir(self.path)):\n",
        "            if file.endswith(\".pth\"):\n",
        "                vec_field = load_compressed_tensor(self.path+file)\n",
        "                img = Image.open(f\"{self.path+file[:-10]}input.jpg\", \"r\")\n",
        "                \n",
        "                _,_,h,w = vec_field.size()\n",
        "                cut_pixel = abs(w-h)//2\n",
        "                if w > h :\n",
        "                  vec_field = vec_field[:,:,:,cut_pixel:-cut_pixel]\n",
        "                  img = img.crop((cut_pixel, 0, w-cut_pixel, h))\n",
        "                elif w < h : \n",
        "                  vec_field = vec_field[:,:,cut_pixel:-cut_pixel,:]\n",
        "                  img = img.crop((0, cut_pixel, w, h-cut_pixel))\n",
        "\n",
        "                vec_field = self.resize(vec_field).squeeze(0)\n",
        "\n",
        "                img = self.resize(img)\n",
        "                img = T.ToTensor()(img)\n",
        "                self.imgs.append(img)\n",
        "                self.vecs.append(vec_field)\n",
        "                \n",
        "        print(\"Done!\")\n",
        "      \n",
        "    def __len__(self):\n",
        "      return len(self.imgs)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "      return self.imgs[idx], self.vecs[idx]\n",
        "    \n",
        "    def select(self, idx):\n",
        "      return ImageVectorFlowDataset(self.imgs[idx], self.vecs[idx], True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DOWNLOAD TRAINING DATA FROM https://eulerian.cs.washington.edu/dataset/ \n",
        "# PUT THE DATA IN THE \"/data/vector_field_prediction/\" FOLDER\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5488d8c16c34150a7c8f6ef117e3c00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 256, 256]), torch.Size([2, 256, 256]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = ImageVectorFlowDataset((img_size,img_size), \"../data/vector_flow_prediction/\")\n",
        "dataset[0][0].shape, dataset[0][1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "train_dataset, eval_dataset = torch.utils.data.random_split(dataset, [train_size, len(dataset) - train_size])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=1, shuffle=True)\n",
        "#dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom loss function for vector fields\n",
        "class VectorFieldLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VectorFieldLoss, self).__init__()\n",
        "\n",
        "    def forward(self, predicted_flows, target_flows):\n",
        "        # Separate magnitude and direction from predicted flows\n",
        "        predicted_magnitudes = torch.norm(predicted_flows, dim=1, keepdim=True)\n",
        "        predicted_directions = predicted_flows / (predicted_magnitudes + 1e-7)  # Add a small constant to avoid division by zero\n",
        "\n",
        "        # Separate magnitude and direction from target flows\n",
        "        target_magnitudes = torch.norm(target_flows, dim=1, keepdim=True)\n",
        "        target_directions = target_flows / (target_magnitudes + 1e-7)  # Add a small constant to avoid division by zero\n",
        "\n",
        "        # Calculate magnitude loss using Smooth L1 loss\n",
        "        magnitude_loss = F.smooth_l1_loss(predicted_magnitudes, target_magnitudes)\n",
        "\n",
        "        # Calculate direction loss, handling zero magnitude vectors\n",
        "        direction_mask = target_magnitudes > 1e-7  # Mask to filter out zero magnitude vectors\n",
        "        num_nonzero_magnitudes = torch.sum(direction_mask).item()\n",
        "        if num_nonzero_magnitudes > 0:\n",
        "            predicted_directions_nonzero = predicted_directions[direction_mask.expand_as(predicted_directions)]\n",
        "            target_directions_nonzero = target_directions[direction_mask.expand_as(target_directions)]\n",
        "            predicted_directions_nonzero = predicted_directions_nonzero.view(-1, 2)\n",
        "            target_directions_nonzero = target_directions_nonzero.view(-1, 2)\n",
        "            direction_loss = 1 - F.cosine_similarity(predicted_directions_nonzero, target_directions_nonzero, dim=1).mean()\n",
        "        else:\n",
        "            direction_loss = torch.tensor(0.0)\n",
        "\n",
        "        # Total loss is the sum of magnitude loss and direction loss\n",
        "        total_loss = magnitude_loss + direction_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# alternative loss function for vector fields\n",
        "class VectorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VectorLoss, self).__init__()\n",
        "        self.cos_sim = torch.nn.CosineSimilarity(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, output, target):\n",
        "        \n",
        "        direction_cos_sim = self.cos_sim(output, target)\n",
        "        direction_loss = 0.5 - direction_cos_sim/2\n",
        "\n",
        "        target_norm = torch.norm(target, dim=1)\n",
        "        output_norm = torch.norm(output, dim=1)\n",
        "        diff = (target_norm - output_norm)\n",
        "        magnitude_loss = diff*diff\n",
        "        \n",
        "        # Do not take in account the directon of vectors that are almost 0 on the training set\n",
        "        minimal_threshold = 0.001\n",
        "        direction_loss = torch.where(target_norm > minimal_threshold, direction_loss, 0)    \n",
        "\n",
        "        total_loss = 10 * direction_loss + magnitude_loss * (1 - direction_loss) * (1 - direction_loss)\n",
        "\n",
        "        return torch.mean(total_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from unet_model import UNet\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#model = ImageToVectorFlow().to(device)\n",
        "model = UNet(3,2).to(device)\n",
        "criterion = VectorFieldLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-4)\n",
        "\n",
        "#training loop\n",
        "i = 0\n",
        "\n",
        "model.train()\n",
        "\n",
        "train_losses = []\n",
        "eval_losses = []\n",
        "\n",
        "best_loss = float(\"inf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for epoch in tqdm(range(200)):\n",
        "    epoch_loss = 0\n",
        "    for img, vec in tqdm(train_dataloader):\n",
        "        transform = T.Compose([T.RandomAffine(0, translate=(0.05, 0.05)), T.RandomHorizontalFlip()])\n",
        "        image_transform = T.Compose([transform , T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1)])\n",
        "        img = image_transform(img).to(device)\n",
        "        vec = transform(vec).to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(img)\n",
        "        loss = criterion(output, vec)\n",
        "        loss.backward()\n",
        "        epoch_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        i += 1\n",
        "    train_losses.append(epoch_loss/len(train_dataloader))\n",
        "    print(f\"Epoch {epoch} loss: {epoch_loss/len(train_dataloader)}\")\n",
        "    with torch.no_grad():\n",
        "        epoch_loss = 0\n",
        "        for img, vec in tqdm(eval_dataloader):\n",
        "            img = img.to(device)\n",
        "            vec = vec.to(device)\n",
        "            output = model(img)\n",
        "            loss = criterion(output, vec)\n",
        "            epoch_loss += loss.item()\n",
        "        eval_losses.append(epoch_loss/len(eval_dataloader))\n",
        "        print(f\"Epoch {epoch} eval loss: {epoch_loss/len(eval_dataloader)}\")\n",
        "    \n",
        "    #save model if it is the best regarding eval loss\n",
        "    if eval_losses[-1] < best_loss:\n",
        "        best_loss = eval_losses[-1]\n",
        "        print(\"New best model!, saving...\")\n",
        "        torch.save(model.state_dict(), \"model_bloup.pth\")\n",
        "    \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3453d868ba5347db94f88c70e6755d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4217ab73b24e40148db41114dfa59ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486764ea5b304575825e41156ddba8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c126c644853c45daa7cb926b66e35fde",
            "placeholder": "​",
            "style": "IPY_MODEL_9e7dcb95a10e406e96b05f314021f9df",
            "value": " 528M/528M [00:05&lt;00:00, 79.8MB/s]"
          }
        },
        "4eba052c1c5a4b9a87181e418574dbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a3d7f1aed1345a08d493b8c9a868cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc802a261dd4440981fae71b4fe526c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6bce05236514d43a4f6b92b1ef6cde4",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eba052c1c5a4b9a87181e418574dbcc",
            "value": 553433881
          }
        },
        "9b2758f3509f48408dbe38746b6ed597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3d7f1aed1345a08d493b8c9a868cd7",
            "placeholder": "​",
            "style": "IPY_MODEL_3453d868ba5347db94f88c70e6755d15",
            "value": "100%"
          }
        },
        "9e7dcb95a10e406e96b05f314021f9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c126c644853c45daa7cb926b66e35fde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6eeb9cacc54c73b8d77dbe97e4e60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b2758f3509f48408dbe38746b6ed597",
              "IPY_MODEL_7fc802a261dd4440981fae71b4fe526c",
              "IPY_MODEL_486764ea5b304575825e41156ddba8e0"
            ],
            "layout": "IPY_MODEL_4217ab73b24e40148db41114dfa59ff7"
          }
        },
        "f6bce05236514d43a4f6b92b1ef6cde4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
